{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "import ray\n",
    "import ray.cloudpickle as pickle\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_ids = [3166028376916322699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 13:01:02,477\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.3.202:6379...\n",
      "2023-03-03 13:01:02,484\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-03 13:01:02,488\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_987ad3bfc6c80bd19a712fd06485b82b.zip' (0.14MiB) to Ray cluster...\n",
      "2023-03-03 13:01:02,490\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_987ad3bfc6c80bd19a712fd06485b82b.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard', python_version='3.10.9', ray_version='3.0.0.dev0', ray_commit='ff66e0ef1bc248a547a88f3eb96512d986b9ed57', address_info={'node_ip_address': '10.0.3.202', 'raylet_ip_address': '10.0.3.202', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-03_09-53-53_365619_141/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-03_09-53-53_365619_141/sockets/raylet', 'webui_url': 'console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2023-03-03_09-53-53_365619_141', 'metrics_export_port': 8085, 'gcs_address': '10.0.3.202:6379', 'address': '10.0.3.202:6379', 'dashboard_agent_listen_port': 52365, 'node_id': '36002c5e4289885460fe73ca4ed70f514950e5bb665bf61ca3850707'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import get_call_data, get_transcript_data, Monologue, Sentence\n",
    "\n",
    "calls_data = get_call_data(call_ids).get(\"calls\")\n",
    "\n",
    "call_summary = defaultdict(dict)\n",
    "for call_data in calls_data:\n",
    "    call_id = call_data[\"metaData\"][\"id\"]\n",
    "    call_title = call_data[\"metaData\"][\"title\"]\n",
    "    media_data = call_data.get(\"media\")\n",
    "    if media_data:\n",
    "        call_summary[call_id].update({\n",
    "            \"call_id\": call_id,\n",
    "            \"title\": call_title,\n",
    "            \"audio\": media_data.get(\"audioUrl\"),\n",
    "            \"video\": media_data.get(\"videoUrl\"),\n",
    "        })\n",
    "\n",
    "transcripts_data = get_transcript_data(call_ids).get(\"callTranscripts\")\n",
    "transcript_monologues = []\n",
    "transcript_text = \"\"\n",
    "for t_data in transcripts_data:\n",
    "    call_id = t_data[\"callId\"]\n",
    "    call_transcript = []\n",
    "\n",
    "    for mono_data in t_data[\"transcript\"]:\n",
    "        speaker_id = mono_data[\"speakerId\"]\n",
    "        topic = mono_data[\"topic\"]\n",
    "        sentences = []\n",
    "        monologue_str = []\n",
    "        for s in mono_data[\"sentences\"]:\n",
    "            sentences.append(\n",
    "                Sentence(s[\"text\"], s[\"start\"], s[\"end\"])\n",
    "            )\n",
    "            monologue_str.append(s[\"text\"])\n",
    "            \n",
    "        mono = Monologue(sentences, speaker_id, topic, call_id=int(call_id))\n",
    "        transcript_monologues.append(mono)\n",
    "\n",
    "        monologue_str = \" \".join(monologue_str)\n",
    "        call_transcript.append(str(mono))\n",
    "        # transcript_text += \"\\n\".join(monologue_str)\n",
    "        # transcript_text += \"------\\n\\n\"\n",
    "    \n",
    "    call_summary[call_id].update({\n",
    "        \"transcript\": \"\\n\".join(call_transcript)\n",
    "    })\n",
    "    transcript_text += \"\\n\".join(call_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(_get_read_tasks pid=129460) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:233: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=129460)   pq_ds.pieces, **prefetch_remote_args\n",
      "(_get_read_tasks pid=129460) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:311: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=129460)   num_files = len(self._pq_ds.pieces)\n",
      "(_get_read_tasks pid=129460) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:324: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=129460)   self._pq_ds.pieces[idx]\n",
      "Parquet Files Sample:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "2023-03-03 13:01:09,051\tWARNING read_api.py:337 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Parquet Files Sample: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]s pid=129460) \n",
      "(_get_read_tasks pid=129460) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:263: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=129460)   np.array_split(self._pq_ds.pieces, parallelism),\n",
      "Read progress: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "data = ray.data.read_parquet(\"s3://antoni-test/gong-calls/3166028376916322699.parquet\")\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = pickle.loads(df[\"word_segments\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ms_int(segment):\n",
    "    segment[\"start\"] = round(segment[\"start\"] * 1000)\n",
    "    segment[\"end\"] = round(segment[\"end\"] * 1000)\n",
    "    return Sentence(text=segment[\"text\"], start_ts=segment[\"start\"], end_ts=segment[\"end\"])\n",
    "\n",
    "segments = [to_ms_int(segment) for segment in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_ts(segment, delta):\n",
    "    segment.start_ts -= delta\n",
    "    segment.end_ts -= delta\n",
    "    return segment\n",
    "\n",
    "def align_timestamps(segments, gong_monologues):\n",
    "    delta_start = segments[0].start_ts - gong_monologues[0].start_ts\n",
    "    return [modify_ts(segment, delta_start) for segment in segments]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_segments = align_timestamps(segments, transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s1, s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)  \n",
    "\n",
    "def reverse_enumerate(data: list):\n",
    "    for i in range(len(data)-1, -1, -1):\n",
    "        yield (i, data[i])\n",
    "\n",
    "def assign_gong_speaker(segments, transcript_monologues):\n",
    "    whisper_monologues = []\n",
    "    segments_in_monologue = []\n",
    "    it = iter(transcript_monologues)\n",
    "    monologue = next(it)\n",
    "    next_monologue = next(it)\n",
    "    for segment in segments:\n",
    "        if segment.start_ts >= monologue.end_ts:\n",
    "            whisper_monologues.append(\n",
    "                Monologue(\n",
    "                    segments_in_monologue,\n",
    "                    monologue.speaker_id,\n",
    "                    \"None\",\n",
    "                    monologue.call_id\n",
    "                )\n",
    "            )\n",
    "            segments_in_monologue = []\n",
    "            monologue = next_monologue\n",
    "            try:\n",
    "                next_monologue = next(it)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "        segments_in_monologue.append(segment)\n",
    "    return whisper_monologues\n",
    "\n",
    "def fix_sentences(monologues):\n",
    "    monologues = deepcopy(monologues)\n",
    "    for monologue, next_monologue in pairwise(monologues):\n",
    "        if not next_monologue:\n",
    "            continue\n",
    "        if not re.match(r\"^[A-Z]\", next_monologue.sentences[0].text) or not re.search(r\"[\\.\\!\\?\\-]$\", monologue.sentences[-1].text):\n",
    "            found_capital = False\n",
    "            index = None\n",
    "            for i, sentence in reverse_enumerate(monologue):\n",
    "                if found_capital and re.search(r\"[\\.\\!\\?\\-\\–]$\", sentence.text):\n",
    "                    index = i+1\n",
    "                    break\n",
    "                if re.match(r\"^[A-Z]\", sentence.text):\n",
    "                    print(f\"found_capital {sentence.text}\")\n",
    "                    found_capital = True\n",
    "            if index is not None:\n",
    "                next_monologue.sentences = monologue.sentences[index:] + next_monologue.sentences\n",
    "                monologue.sentences = monologue.sentences[:index]\n",
    "    return monologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_monologues = assign_gong_speaker(aligned_segments, transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found_capital All\n",
      "found_capital And\n",
      "found_capital Yeah,\n",
      "found_capital No,\n"
     ]
    }
   ],
   "source": [
    "whisper_monologues_fixed = fix_sentences(whisper_monologues[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230) SCOTT CECIL: Hey Alex, good to see you.\n",
      " (2583) ALEX POST POST: Hey, you too. How's it going?\n",
      " (4684) SCOTT CECIL: Doing well, doing well. I'm in office today, first time in three months. It's a feeling. It looks like you're at your house?\n",
      " (12427) ALEX POST POST: Yep. Very nice. Yep. So, I traveled last week, but we're back now.\n",
      " (19401) SCOTT CECIL: Okay, very nice. Yeah, I traveled this morning. Alex, remind me, where are you located again?\n",
      " (25248) ALEX POST POST: I am in Grand Rapids, Michigan. Okay, nice. Cool.\n",
      " (29042) SCOTT CECIL: All right, looks like we got David on. David, welcome. Nice to meet you. I don't think we met yet. Nice to meet you. Yeah, cool. And we have some new faces on our side, so maybe we can start with introductions today. The agenda is pretty straightforward today. Really want to dive into RL, the training side of things as well, even show you guys a demo. And on the call I have today, I have Uday. Uday is one of our lead sales engineers who will perform a demo today on the AnyScale platform, as well as Karosh, who leads our RL team and helps innovate on the package of RL-Live, which you guys aren't using today, but maybe it's a possibility down the line. And we want to dive into that. It looks like, David, you posted some questions via email. We saw those, and we will be able to answer all those via this discussion. So maybe quick introductions on your side, Alex, if you want to give a quick intro. I know you and I met already, but just for the rest of the team here.\n",
      " (84223) ALEX POST POST: Yeah, sure. So I'm Alex. I've been at Slingshot for about six months now. I'm a machine learning engineer, and I typically focus on – my background is actually in more along the lines of software development than is machine learning, though I do have a master's in machine learning – or in data science. But so I've been focused mostly on the software side of sort of focusing on the deployment side, really, of how do we take the machine learning models and apply them within our applications. Awesome. Yeah.\n",
      " (126937) SCOTT CECIL: And David, over to you.\n",
      " (129937) DAVID WITMAN: Yeah, so I'm – Dave, can you hear me all? Yeah, loud and clear. Yeah. So like Alex, I joined Slingshot about seven months ago or something. And yeah, prior to Slingshot, a lot of my work was in ML, but I was focused on the problems from scientific machine learning to image detection classification. I did a little bit of reinforcement learning a few years ago, but kind of since I've come to Slingshot, that's been my main area of focus, and we've been really trying to stand up some capability to answer some questions for sequential decision-making. So yeah, I've had some experience, like, looking at Ray, but not – you know. Okay. Cool. So yeah, I've been –\n",
      " (185321) SCOTT CECIL: No, that's good information. Appreciate that. Well, awesome. I think the agenda today, Alex, again, I think we want to show you guys a demo, but I think we quickly want to recap our last conversation you and I had. A lot of people had some questions. Maybe go into Ray and RLib even further and then go through that demo. Alex,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([str(m) for m in whisper_monologues_fixed[:11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230) SCOTT CECIL: Hey Alex, good to see you.\n",
      " (2583) ALEX POST POST: Hey, you too. How's it going?\n",
      " (4684) SCOTT CECIL: Doing well, doing well. I'm in office today, first time in three months. It's a feeling. It looks like you're at your house?\n",
      " (12427) ALEX POST POST: Yep. Very nice. Yep. So, I traveled last week, but we're back now.\n",
      " (19401) SCOTT CECIL: Okay, very nice. Yeah, I traveled this morning. Alex, remind me, where are you located again?\n",
      " (25248) ALEX POST POST: I am in Grand Rapids, Michigan. Okay, nice. Cool. All right,\n",
      " (29766) SCOTT CECIL: looks like we got David on. David, welcome. Nice to meet you. I don't think we met yet. Nice to meet you. Yeah, cool. And we have some new faces on our side, so maybe we can start with introductions today. The agenda is pretty straightforward today. Really want to dive into RL, the training side of things as well, even show you guys a demo. And on the call I have today, I have Uday. Uday is one of our lead sales engineers who will perform a demo today on the AnyScale platform, as well as Karosh, who leads our RL team and helps innovate on the package of RL-Live, which you guys aren't using today, but maybe it's a possibility down the line. And we want to dive into that. It looks like, David, you posted some questions via email. We saw those, and we will be able to answer all those via this discussion. So maybe quick introductions on your side, Alex, if you want to give a quick intro. I know you and I met already, but just for the rest of the team here.\n",
      " (84223) ALEX POST POST: Yeah, sure. So I'm Alex. I've been at Slingshot for about six months now. I'm a machine learning engineer, and I typically focus on – my background is actually in more along the lines of software development than is machine learning, though I do have a master's in machine learning – or in data science. But so I've been focused mostly on the software side of sort of focusing on the deployment side, really, of how do we take the machine learning models and apply them within our applications. Awesome. Yeah. And\n",
      " (128588) SCOTT CECIL: David, over to you. Yeah,\n",
      " (131004) DAVID WITMAN: so I'm – Dave, can you hear me all? Yeah, loud and clear. Yeah. So like Alex, I joined Slingshot about seven months ago or something. And yeah, prior to Slingshot, a lot of my work was in ML, but I was focused on the problems from scientific machine learning to image detection classification. I did a little bit of reinforcement learning a few years ago, but kind of since I've come to Slingshot, that's been my main area of focus, and we've been really trying to stand up some capability to answer some questions for sequential decision-making. So yeah, I've had some experience, like, looking at Ray, but not – you know. Okay. Cool. So yeah, I've been – No, that's good\n",
      " (185967) SCOTT CECIL: information. Appreciate that. Well, awesome. I think the agenda today, Alex, again, I think we want to show you guys a demo, but I think we quickly want to recap our last conversation you and I had. A lot of people had some questions. Maybe go into Ray and RLib even further and then go through that demo. Alex,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([str(m) for m in whisper_monologues[:11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230) SCOTT CECIL: Hey, Alex. Good to see you.\n",
      " (2620) ALEX POST POST: Hey, you too. How's it going?\n",
      " (4740) SCOTT CECIL: Doing well. Doing well. I'm up today first time in three months. So, all right. I'm feeling it looks like you're in your, you're at your house?\n",
      " (12130) ALEX POST POST: Yep. Yep. So a, last week, but we're back now.\n",
      " (19370) SCOTT CECIL: Okay, very nice. Yeah, I'll travel this morning where Alex remind me where are you located again?\n",
      " (25170) ALEX POST POST: I am in green rapids Michigan. Okay. Nice. Cool. All right.\n",
      " (29660) SCOTT CECIL: It looks like we got David on David welcome. Nice to meet you. I don't think we met yet. Nice to me too. Cool. We have some new faces on our side. So maybe we can start with introductions today. Agenda is pretty straightforward today. Really wanna dive into Rllib, the training side of things as well. Even show you a demo. And on the call today of a, is one of our lead sales engineers who will perform a demo today on the Anyscale platform as well as gosh, who leads our team and helps innovate on the package of Rllib which you guys aren't using today, but maybe it's a possibility down the line and we want to dive into that. And it looks like David, you posted some questions via email. We saw those and we will be able to answer all those via this discussion. So maybe quick introductions on your side, you want to give a quick, I know you and I met already, but just for the rest of the team here?\n",
      " (84330) ALEX POST POST: Yeah. Sure. So, I'm Alex, I've been at Slingshot for about six months now a machine learning engineer. And I typically focus on my background is actually in more along the lines of software development than is machine learning though I do have a masters in machine learning or in data science. But so I've been focused mostly on the software side of… sort of focusing on the deployment side really of how do we take the machine learning models and apply them within our applications. So, yeah.\n",
      " (128710) SCOTT CECIL: And David over to you?\n",
      " (130740) DAVID WITMAN: Yeah, David, can you hear me all? Yeah, loud and clear. Yeah. So like Alex, I joined Slingshot or something. And yeah, prior to Slingshot, a lot of my work in was in, but I was focused on problems from simchine in action classification. I did a little bit of reinforcement learning a few years ago but kind of since I've come to Slingshot, that's my main area of focus and really trying to stand up some to answer some us questions for sequential decision making. So, yeah, I've had some experience like looking at Ray but not, you know, okay, cool. Didn't dive in a?\n",
      " (185820) SCOTT CECIL: Rllib, appreciate that. Well, awesome. I think the today, Alex, again, I think we want to show you guys a demo, but I think we were quick, want to recap our last conversation. You had some questions maybe go into Ray and Rllib even further and then go through that demo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([str(m) for m in transcript_monologues[:11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_monologues[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
