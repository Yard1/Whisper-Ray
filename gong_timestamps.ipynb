{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "import ray\n",
    "import ray.cloudpickle as pickle\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_ids = [3166028376916322699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 14:23:46,106\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.3.202:6379...\n",
      "2023-03-03 14:23:46,113\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-03 14:23:46,117\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_7edc2ae5aff4f6292846244b76d85f65.zip' (0.29MiB) to Ray cluster...\n",
      "2023-03-03 14:23:46,121\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_7edc2ae5aff4f6292846244b76d85f65.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard', python_version='3.10.9', ray_version='3.0.0.dev0', ray_commit='ff66e0ef1bc248a547a88f3eb96512d986b9ed57', address_info={'node_ip_address': '10.0.3.202', 'raylet_ip_address': '10.0.3.202', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-03_09-53-53_365619_141/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-03_09-53-53_365619_141/sockets/raylet', 'webui_url': 'console.anyscale-staging.com/api/v2/sessions/ses_kb3ste2ly7ykmwplrp9lcbkrra/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2023-03-03_09-53-53_365619_141', 'metrics_export_port': 8085, 'gcs_address': '10.0.3.202:6379', 'address': '10.0.3.202:6379', 'dashboard_agent_listen_port': 52365, 'node_id': '36002c5e4289885460fe73ca4ed70f514950e5bb665bf61ca3850707'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import get_call_data, get_transcript_data, Monologue, Sentence\n",
    "\n",
    "calls_data = get_call_data(call_ids).get(\"calls\")\n",
    "\n",
    "call_summary = defaultdict(dict)\n",
    "for call_data in calls_data:\n",
    "    call_id = call_data[\"metaData\"][\"id\"]\n",
    "    call_title = call_data[\"metaData\"][\"title\"]\n",
    "    media_data = call_data.get(\"media\")\n",
    "    if media_data:\n",
    "        call_summary[call_id].update({\n",
    "            \"call_id\": call_id,\n",
    "            \"title\": call_title,\n",
    "            \"audio\": media_data.get(\"audioUrl\"),\n",
    "            \"video\": media_data.get(\"videoUrl\"),\n",
    "        })\n",
    "\n",
    "transcripts_data = get_transcript_data(call_ids).get(\"callTranscripts\")\n",
    "transcript_monologues = []\n",
    "transcript_text = \"\"\n",
    "for t_data in transcripts_data:\n",
    "    call_id = t_data[\"callId\"]\n",
    "    call_transcript = []\n",
    "\n",
    "    for mono_data in t_data[\"transcript\"]:\n",
    "        speaker_id = mono_data[\"speakerId\"]\n",
    "        topic = mono_data[\"topic\"]\n",
    "        sentences = []\n",
    "        monologue_str = []\n",
    "        for s in mono_data[\"sentences\"]:\n",
    "            sentences.append(\n",
    "                Sentence(s[\"text\"], s[\"start\"], s[\"end\"])\n",
    "            )\n",
    "            monologue_str.append(s[\"text\"])\n",
    "            \n",
    "        mono = Monologue(sentences, speaker_id, topic, call_id=int(call_id))\n",
    "        transcript_monologues.append(mono)\n",
    "\n",
    "        monologue_str = \" \".join(monologue_str)\n",
    "        call_transcript.append(str(mono))\n",
    "        # transcript_text += \"\\n\".join(monologue_str)\n",
    "        # transcript_text += \"------\\n\\n\"\n",
    "    \n",
    "    call_summary[call_id].update({\n",
    "        \"transcript\": \"\\n\".join(call_transcript)\n",
    "    })\n",
    "    transcript_text += \"\\n\".join(call_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(_get_read_tasks pid=182690) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:233: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=182690)   pq_ds.pieces, **prefetch_remote_args\n",
      "(_get_read_tasks pid=182690) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:311: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=182690)   num_files = len(self._pq_ds.pieces)\n",
      "(_get_read_tasks pid=182690) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:324: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=182690)   self._pq_ds.pieces[idx]\n",
      "Parquet Files Sample:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "2023-03-03 14:23:53,039\tWARNING read_api.py:337 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Parquet Files Sample: 100%|██████████| 1/1 [00:03<00:00,  3.27s/it]s pid=182690) \n",
      "(_get_read_tasks pid=182690) /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/datasource/parquet_datasource.py:263: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "(_get_read_tasks pid=182690)   np.array_split(self._pq_ds.pieces, parallelism),\n",
      "Read progress: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "data = ray.data.read_parquet(\"s3://antoni-test/gong-calls/3166028376916322699.parquet\")\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = pickle.loads(df[\"word_segments\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ms_int(segment):\n",
    "    segment[\"start\"] = round(segment[\"start\"] * 1000)\n",
    "    segment[\"end\"] = round(segment[\"end\"] * 1000)\n",
    "    return Sentence(text=segment[\"text\"], start_ts=segment[\"start\"], end_ts=segment[\"end\"])\n",
    "\n",
    "segments = [to_ms_int(segment) for segment in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_ts(segment, delta):\n",
    "    segment.start_ts -= delta\n",
    "    segment.end_ts -= delta\n",
    "    return segment\n",
    "\n",
    "def align_timestamps(segments, gong_monologues):\n",
    "    delta_start = segments[0].start_ts - gong_monologues[0].start_ts\n",
    "    return [modify_ts(segment, delta_start) for segment in segments]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_segments = align_timestamps(segments, transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s1, s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "end_of_sentence_regex = r\"[\\.\\!\\?\\-\\–]$\"\n",
    "start_of_sentence_regex = r\"^[A-Z]\"\n",
    "\n",
    "def reverse_enumerate(data: list):\n",
    "    for i in range(len(data)-1, -1, -1):\n",
    "        yield (i, data[i])\n",
    "\n",
    "def merge_speakers(transcript_monologues):\n",
    "    original_transcript_monologues = transcript_monologues\n",
    "    transcript_monologues = deepcopy(transcript_monologues)\n",
    "    for i in range(3):\n",
    "        merged_monologues = []\n",
    "        last_monologue = transcript_monologues[0]\n",
    "        for monologue, next_monologue in pairwise(transcript_monologues):\n",
    "\n",
    "            if monologue.sentences and last_monologue.sentences and last_monologue.speaker == next_monologue.speaker and last_monologue.speaker != monologue.speaker:\n",
    "                if not re.match(start_of_sentence_regex, monologue[0].text) and not re.search(end_of_sentence_regex, monologue[-1].text):\n",
    "                    merged_monologues.pop()\n",
    "                    monologue.sentences = last_monologue.sentences + monologue.sentences + next_monologue.sentences\n",
    "                    next_monologue.sentences = []\n",
    "\n",
    "            if monologue.speaker == next_monologue.speaker:\n",
    "                monologue.sentences = monologue.sentences + next_monologue.sentences\n",
    "                next_monologue.sentences = []\n",
    "            if monologue.sentences:\n",
    "                merged_monologues.append(monologue)\n",
    "            last_monologue = monologue\n",
    "        if next_monologue.sentences:\n",
    "            merged_monologues.append(next_monologue)\n",
    "        transcript_monologues = merged_monologues\n",
    "\n",
    "    assert \"\".join([\"\".join([y.text for y in x]) for x in original_transcript_monologues]) == \"\".join([\"\".join([y.text for y in x]) for x in transcript_monologues])\n",
    "    return transcript_monologues\n",
    "\n",
    "def assign_gong_speaker(segments, transcript_monologues):\n",
    "    whisper_monologues = []\n",
    "    segments_in_monologue = []\n",
    "    it = iter(transcript_monologues)\n",
    "    monologue = next(it)\n",
    "    next_monologue = next(it)\n",
    "    for segment in segments:\n",
    "        if segment.start_ts >= monologue.end_ts:\n",
    "            whisper_monologues.append(\n",
    "                Monologue(\n",
    "                    segments_in_monologue,\n",
    "                    monologue.speaker_id,\n",
    "                    \"None\",\n",
    "                    monologue.call_id\n",
    "                )\n",
    "            )\n",
    "            segments_in_monologue = []\n",
    "            monologue = next_monologue\n",
    "            try:\n",
    "                next_monologue = next(it)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "        segments_in_monologue.append(segment)\n",
    "    if segments_in_monologue:\n",
    "        whisper_monologues.append(\n",
    "            Monologue(\n",
    "                segments_in_monologue,\n",
    "                monologue.speaker_id,\n",
    "                \"None\",\n",
    "                monologue.call_id\n",
    "            )\n",
    "        )\n",
    "    return whisper_monologues\n",
    "\n",
    "def fix_sentences(monologues):\n",
    "    monologues = deepcopy(monologues)\n",
    "    for monologue, next_monologue in pairwise(monologues):\n",
    "        if not next_monologue:\n",
    "            continue\n",
    "        if not re.match(start_of_sentence_regex, next_monologue.sentences[0].text) or not re.search(end_of_sentence_regex, monologue.sentences[-1].text):\n",
    "            delta_front = -1\n",
    "            delta_back = -1\n",
    "            num_words_back = -1\n",
    "            num_words_front = -1\n",
    "            found_capital = None\n",
    "            index_front = None\n",
    "            index_back = None\n",
    "            for i, sentence in reverse_enumerate(monologue):\n",
    "                num_words_back += 1\n",
    "                if found_capital is not None and re.search(end_of_sentence_regex, sentence.text):\n",
    "                    index_back = i+1\n",
    "                    delta_back = found_capital - sentence.end_ts\n",
    "                    break\n",
    "                if re.match(start_of_sentence_regex, sentence.text):\n",
    "                    found_capital = sentence.start_ts\n",
    "\n",
    "            found_end = None\n",
    "\n",
    "            for i, sentence in enumerate(next_monologue):\n",
    "                num_words_front += 1\n",
    "                if found_end is not None and re.match(start_of_sentence_regex, sentence.text):\n",
    "                    index_front = i\n",
    "                    delta_front = sentence.start_ts - found_end\n",
    "                    break\n",
    "\n",
    "                if re.search(end_of_sentence_regex, sentence.text):\n",
    "                    found_end = sentence.end_ts\n",
    "\n",
    "           # print(f\"delta_front {delta_front} delta_back {delta_back}\")\n",
    "           # print(f\"num_words_front {num_words_front} num_words_back {num_words_back}\")\n",
    "           # print(str(monologue))\n",
    "           # print(str(next_monologue))\n",
    "\n",
    "            if num_words_back == 1:\n",
    "                delta_back = float(\"inf\")\n",
    "\n",
    "            if num_words_front == 1:\n",
    "                delta_front = float(\"inf\")\n",
    "\n",
    "            if delta_front > delta_back and index_front is not None:\n",
    "                index = index_front\n",
    "                monologue.sentences = monologue.sentences + next_monologue.sentences[:index] \n",
    "                next_monologue.sentences = next_monologue.sentences[index:]\n",
    "            elif index_back is not None:\n",
    "                index = index_back\n",
    "                next_monologue.sentences = monologue.sentences[index:] + next_monologue.sentences\n",
    "                monologue.sentences = monologue.sentences[:index]\n",
    "    return monologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_transcript_monologues = merge_speakers(transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_monologues = assign_gong_speaker(aligned_segments, transcript_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_monologues_merged = merge_speakers(whisper_monologues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_monologues_fixed = merge_speakers(fix_sentences(whisper_monologues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whisper_monologues_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_monologues_fixed_merged = merge_speakers(whisper_monologues_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whisper_monologues_fixed_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fixed.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([str(m) for m in whisper_monologues_fixed_merged]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"whisper_um.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([str(m) for m in whisper_monologues]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"whisper.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([str(m) for m in whisper_monologues_merged]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gong.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([str(m) for m in merged_transcript_monologues]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230) SCOTT CECIL: Hey, Alex. Good to see you.\n",
      " (2620) ALEX POST POST: Hey, you too. How's it going?\n",
      " (4740) SCOTT CECIL: Doing well. Doing well. I'm up today first time in three months. So, all right. I'm feeling it looks like you're in your, you're at your house?\n",
      " (12130) ALEX POST POST: Yep. Yep. So a, last week, but we're back now.\n",
      " (19370) SCOTT CECIL: Okay, very nice. Yeah, I'll travel this morning where Alex remind me where are you located again?\n",
      " (25170) ALEX POST POST: I am in green rapids Michigan. Okay. Nice. Cool. All right.\n",
      " (29660) SCOTT CECIL: It looks like we got David on David welcome. Nice to meet you. I don't think we met yet. Nice to me too. Cool. We have some new faces on our side. So maybe we can start with introductions today. Agenda is pretty straightforward today. Really wanna dive into Rllib, the training side of things as well. Even show you a demo. And on the call today of a, is one of our lead sales engineers who will perform a demo today on the Anyscale platform as well as gosh, who leads our team and helps innovate on the package of Rllib which you guys aren't using today, but maybe it's a possibility down the line and we want to dive into that. And it looks like David, you posted some questions via email. We saw those and we will be able to answer all those via this discussion. So maybe quick introductions on your side, you want to give a quick, I know you and I met already, but just for the rest of the team here?\n",
      " (84330) ALEX POST POST: Yeah. Sure. So, I'm Alex, I've been at Slingshot for about six months now a machine learning engineer. And I typically focus on my background is actually in more along the lines of software development than is machine learning though I do have a masters in machine learning or in data science. But so I've been focused mostly on the software side of… sort of focusing on the deployment side really of how do we take the machine learning models and apply them within our applications. So, yeah.\n",
      " (128710) SCOTT CECIL: And David over to you?\n",
      " (130740) DAVID WITMAN: Yeah, David, can you hear me all? Yeah, loud and clear. Yeah. So like Alex, I joined Slingshot or something. And yeah, prior to Slingshot, a lot of my work in was in, but I was focused on problems from simchine in action classification. I did a little bit of reinforcement learning a few years ago but kind of since I've come to Slingshot, that's my main area of focus and really trying to stand up some to answer some us questions for sequential decision making. So, yeah, I've had some experience like looking at Ray but not, you know, okay, cool. Didn't dive in a?\n",
      " (185820) SCOTT CECIL: Rllib, appreciate that. Well, awesome. I think the today, Alex, again, I think we want to show you guys a demo, but I think we were quick, want to recap our last conversation. You had some questions maybe go into Ray and Rllib even further and then go through that demo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([str(m) for m in transcript_monologues[:11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_monologues[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
